{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 線形モデル選択と正則化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは線形モデルを改良する別の方法を考える。線形モデルには推論の点で明確な長所があり、現実の問題を扱う際には非線形法と比較して消して劣ることはない。しかし、他の方法の方が予測精度が高く、そして、モデルの解釈が容易になる状況がある。\n",
    "- 予測精度：応答変数と予測変数の間の真の関係が近似的に線形であるならば、最小2乗法による推定値のバイアスは小さい。$n > p$の場合は分散も小さくなる傾向にある。ゆえにテストデータにおいて良い性能を発揮する。しかし、もし$n$が$p$よりあまり大きくない場合、最小2乗法による予測はばらつきが生じ、過学習となり、訓練に使われなかったデータにおける予測精度は落ちることになる。また$p > n$の場合、最小2乗法では回帰係数が一意に定まらない（使えなくなる）。\n",
    "- モデルの解釈：予測変数のうちいくつか、または多くが実は応答変数と関係がないということはよくある。このような無意味な変数を入れてしまうことでモデルは必要以上に複雑になってしまう。これら不必要な変数を取り除く、つまり、該当する係数を0にすることにより、より解釈が容易なモデルにすることができる。最小2乗法では係数が正確に0になることはそれほど起こらない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最小2乗法を線形モデル$ Y = \\beta_0 + \\beta_1 X_1 + \\cdots + \\beta_p X_p + \\varepsilon $に当てはめることに代わる方法はいくつかあるが、ここでは**部分集合選択**と**縮小推定**について論じる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 部分集合選択"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最良部分集合選択\n",
    "\n",
    "step1: $\\mathcal{M}_0$を予測変数を持たないヌルモデルとする。このモデルは予測値として単に標本平均を用いる。\n",
    "\n",
    "step2: $k=1,\\ldots,p$について：\n",
    "\n",
    "(a)$k$個の予測変数をもつモデル$\\binom pk$個全てに回帰を当てはめる。\n",
    "\n",
    "(b)$\\binom pk$個のモデル全てからベストなものを選ぶ。これを$\\mathcal{M}_k$とする。ベストなモデルとはRSSが最小となるもの、または$R^2$が最大となるものである。\n",
    "\n",
    "step3: $\\mathcal{M}_0, \\ldots, \\mathcal{M}_p$のうち、ただ一つのベストなモデルを選ぶ。判断規準は交差検証予測誤差、Cp(AIC)、BIC、自由度調整済み決定係数$R^2$などである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最良部分集合選択には計算量の面で問題がある。一般的に$p$個の予測変数があれば考慮するモデルの数は$2^p$個となる。$p=10$であればおよそ1000個のモデルを検討するし、$20$ならば100万個以上のモデルを検討しなければならない。そのため最良部分選択集合選択は最新のコンピュータをもってしても$p=40$以上の場合には計算量的に困難である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ステップワイズ法：変数増加法と変数減少法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 変数増加法\n",
    "\n",
    "step1: $\\mathcal{M}_0$を予測変数を持たないヌルモデルとする。\n",
    "\n",
    "step2: $k=1,\\ldots,p-1$について以下を繰り返す：\n",
    "\n",
    "(a) $\\mathrm{M}_k$の予測変数に含まれない変数のうち、どれか一つを加えることによって構成される$p-k$個のモデルを考える。\n",
    "\n",
    "(b) $p - k$個のモデルのうち、ベストなものを選び、これを$\\mathcal{M}_{k+1}$とする。ここにベストとは、RSSが最小または$R^2$が最大であることとする。 \n",
    "\n",
    "step3: 交差検証予測誤差、Cp（AIC）、BIC、自由度調整済み$R^2$などにより$\\mathcal{M}_0, \\ldots, \\mathcal{M}_p$個の中からベストなモデルを選ぶ。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 変数増加法は最良部分集合選択に代わる方法として計算量的に効率の良い方法である。最良部分選択集合では$2^p$個のモデルを当てはめることになるのに対し、変数増加法はまず最小にヌルモデル、そして$k$回目（$k=0, \\ldots, p-1$）の繰り返しループで$p-k$個のモデルを当てはめる。これによっって検討するモデルの総数は$1 + \\sum_{k=0}^{p-1}(p - k) = 1 + p(p+1)/2$個となる。これは大きな違いである（例：$p=20$のとき、最良部分集合選択では1048576個のモデルを検討する必要があるが、変数増加法ならば211個のみでよい）。\n",
    "- 変数増加法は計算量の面で最良部分集合選択に勝っており、実用上良い性能を示すが、$p$個の変数で考えうる$2^p$個全てのモデルのうちベストなものを発見できるという保証はない。例として3個の予測変数（p=3）をもつデータセットを考える。1変数でのベストなモデルは$X_1$を含み、2変数でのベストなモデルは$X_2$と$X_3$を使ったものであるとする。この場合、変数増加法では2変数のベストモデルを見つけることができない。$\\mathcal{M}_1$は$X_1$を含むため、$\\mathcal{M}_2$は$X_1$ともう一つ別の変数を含むことになるからである。\n",
    "- 変数増加法は高次元（$n < p$）の場合にも適用することができる。しかしこの場合、モデルは$\\mathcal{M}_0, \\ldots, \\mathcal{M}_{n-1}$までとなる。これは$p \\ge n$の場合、モデルを当てはめるのに使われる最小2乗法の解が一意に定まらないからである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 変数減少法\n",
    "\n",
    "step1: $p$個すべての予測変数を含むフルモデルを$\\mathcal{M}_p$とする。\n",
    "\n",
    "step2: $k=p, p-1, \\ldots, 1$について以下のループを繰り返す；\n",
    "\n",
    "(a) $\\mathcal{M}_k$から予測変数を1つだけ除いてできる$k$個のモデルを考える。これらは$k-1$個の予測変数を持つ。\n",
    "\n",
    "(b) これら$k$個のモデルのうちベストなモデルを選び、これを$\\mathcal{M}_{k-1}$とする。ここに、ベストとはRSSが最小なもの、または$R^2$が最大なものとする。\n",
    "\n",
    "step3: $\\mathcal{M}_0, \\ldots, \\mathcal{p}$のうち、ベストなモデルを交差検証予測誤差、Cp（AIC）、BIC、自由度調整済み$R^2$などにより選ぶ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 変数増加法と同様、変数減少法は最良部分集合選択に代わる効率的な方法である。変数増加法と同様に変数減少法が探索するのは$1 + p(p+1)/2$個のモデルのみである。したがって最良部分集合選択が適用できないほど$p$が大きなケースにも適用することができる。\n",
    "- 変数増加法と同じく、$p$個の予測変数のすべての部分集合でベストなモデルを発見できるという保証はない。\n",
    "- 変数減少法を行うには、（フルモデルをあてはめるため）サンプルサイズ$n$が変数の数$p$よりも大きいという条件を必要とする。これに対し、変数増加法は、$n < p$の場合にも使うことができる。したがって$p$が非常に大きい場合には唯一の実行可能な方法といえる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記3つの方法を実装するには、モデルを評価する方法が必要である。実は、すべての予測変数を含むモデルが常にRSSを最小、$R^2$を最大とする。なぜならこれらの量は訓練誤差に関係しているからである。しかし本来は訓練誤差ではなく、テスト誤差を最小にするようなモデルを選びたい。訓練誤差をテスト誤差の推定値として使用することは、訓練MSEが小さければテストMSEが小さいという保証がないため、あまりよくない。したがってRSSや$R^2$は予測変数の数が異なるモデルを比較して最適なものを選ぶ際には適していない。\n",
    "\n",
    "テスト誤差について最適なモデルを選ぶため、テスト誤差を推定する必要があるが、良く用いられる手法には2種類ある：\n",
    "    1. 訓練誤差を過学習によるバイアスを考慮して調整することにより、テスト誤差を間接的に推定する。\n",
    "    2. ホールドアウト検証や交差検証法により直接的にテスト誤差を推定する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $C_p$, AIC, BIC, 自由度調整済み$R^2$\n",
    "\n",
    "モデルの予測変数の数を増やせば訓練誤差は減少するが、テスト誤差は減少するとは限らない。よって訓練RSSや訓練$R^2$は変数の数が異なるモデルの中から最適なモデルを選ぶ際には使うことはできない。しかし、モデルの予測変数の数に応じて、訓練誤差を調整する方法はいくつもある。\n",
    "\n",
    "$d$個の予測変数をもつ最小2乗モデルにおいて、$C_p$によるテストMSE推定値は次で計算される：\n",
    "\n",
    "\\begin{equation}\n",
    "    C_p = \\frac{1}{n}(\\mathrm{RSS} + 2 d \\hat{\\sigma}^2)\n",
    "\\end{equation}\n",
    "\n",
    "ここで、$\\hat{\\sigma}^2$は誤差$\\epsilon$の分散の推定量である。$\\hat{\\sigma}^2$が$\\sigma^2$の推定値としてバイアスのないものであるならば、$C_p$はテストMSEの推定値としてバイアスが無いとことが示される。結果として、テスト誤差の低いモデルで$C_p$統計量は小さい値を示すこととなり、最適なモデルを選ぶ際には$C_p$の値が最小となるものを選べばよい。\n",
    "\n",
    "AIC規準は最尤法によるさまざまなクラスのモデルの当てはめに対し定義される：\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathrm{AIC} = \\frac{1}{n \\hat{\\sigma}^2}(\\mathrm{RSS} + 2 d \\hat{\\sigma}^2) \n",
    "\\end{equation}\n",
    "\n",
    "BICはベイズ統計の見地に立って定義されているが、$C_p$、AICに類似した形になっている。\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathrm{BIC} = \\frac{1}{n \\hat{\\sigma}^2}(\\mathrm{RSS} + 2 d \\hat{\\sigma}^2) \n",
    "\\end{equation}\n",
    "\n",
    "$C_p$と同様、テスト誤差が小さいときにBICも小さい値をとる。したがって、一般的にはBICの値が最小になるモデルを選べばよい。\n",
    "\n",
    "自由度調整済み$R^2$も変数の数が異なるモデル族の中から選ぶ際によく使われるアプローチである。通常の$R^2$は$R^2 = 1 - \\mathrm{RSS}/\\mathrm{TSS}(\\mathrm{TSS} := \\sum (y_i - \\bar{y})^2)$であるが、自由度調整済み$R^2$は次のように計算される：\n",
    "\n",
    "\\begin{equation}\n",
    "    \\text{自由度調整済み}R^2 = 1 - \\frac{\\mathrm{RSS}/(n-d-1)}{\\mathrm{TSS}/(n-1)} \n",
    "\\end{equation}\n",
    "\n",
    "テスト誤差が小さいモデルで$C_p$、AIC、BICが小さい値を示すのに対し、自由度調整済み$R^2$は大きい値となる。直観的には、自由度調整済み$R^2$はモデルに含まれるべき変数を含んだうえでそれ以上他のノイズ変数をモデルに加えると、RSSがわずかだけ減少する。ノイズ変数を加えればもちろん$d$は増加し、$\\frac{RSS}{n-d-1}$は増加する。結果として自由度調整済み$R^2$は減少する。$R^2$と異なり、自由度調整済み$R^2$はモデルに不必要な変数を含めるとその対価を支払わなければならないのである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ホールドアウト検証と交差検証\n",
    "\n",
    "ホールドアウト検証や交差検証法を使って直接テスト誤差を推定することもできる。対象となるモデルのホールドアウト検証誤差や交差検証誤差を計算し、推定誤差が最小となるようなモデルを選べばよい。この手法は直接テスト誤差を推定しており、また真のモデルについての仮定がより少ないという点でAIC、BIC、$C_p$、自由度調整済み$R^2$より優れているといえる。モデルの自由度（p）の決定が難しい場合や誤差の分散$\\sigma^2$の推定が難しい場合などでさえ用いることができる。従来$p$が大きい場合や$n$が大きい場合には交差検証に必要な計算量が莫大であることから、モデル選択にはAIC、BIC、$C_p$、自由度調整済み$R^2$がよく使われた。しかし、現在ではコンピュータの高速化により、交差検証をするのに必要な計算量はもはや問題になることはない。したがって、交差検証は検討される多くのモデルのうち最適なものを選ぶ際のより魅力的なアプローチである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 縮小推定\n",
    "\n",
    "**部分集合選択**は、予測変数の部分集合を含む線形モデルに最小2乗法を当てはめた。それに代わる方法として、p個全ての変数をモデルに含み、係数の推定値を制約、あるいは正則化する仕組みを用いてモデルを当てはめる。つまり、係数を0に近づけることを考える。これにより分散がかなり減少するのである。回帰係数を縮小して0に近い値にする（または0にする）方法のうち、最もよく知られているのがリッジ回帰とLassoである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### リッジ回帰\n",
    "\n",
    "最小2乗法では以下を最小化することで$\\beta_0, \\ldots, \\beta_p$を推定していた：\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathrm{RSS} = \\sum_{i=1}^{n} \\left(y_i - \\beta_0 - \\sum_{j=1}^{p}\\beta_j x_{ij}\\right)^2\n",
    "\\end{equation}\n",
    "\n",
    "リッジ回帰は最小2乗法と類似しているが、係数を推定するとき少し異なる関数を最小化することになる：\n",
    "\n",
    "\\begin{equation}\n",
    "    \\sum_{i=1}^{n} \\left(y_i - \\beta_0 - \\sum_{j=1}^{p}\\beta_j x_{ij}\\right)^2 + \\lambda \\sum_{j=1}^p \\beta_j^2 = \\mathrm{RSS} + \\lambda \\sum_{j=1}^{p} \\beta_j^2 \\tag{6.5}\n",
    "\\end{equation}\n",
    "\n",
    "ここで$\\lambda \\ge 0$はチューニングパラメータであり、別途決定する必要がある。式(6.5)には2つの異なる基準のトレードオフがある。最小2乗法と同様、リッジ回帰はRSSを最小化することによりデータによく当てはまる係数を推定する。しかし、$\\beta_1, \\ldots, \\beta_p$が0に近いと、罰則項と呼ばれる第2項$\\lambda \\sum_j \\beta_j^2$も小さいため、$\\beta_j$の推定値を0に近づける（縮小する）効果がある。チューニングパラメータ$\\lambda$はこれらの2項が回帰係数の推定値に与える影響を制御するためにある。$\\lambda = 0$のとき、罰則項は何の影響ももたらさないため、リッジ回帰は最小2乗法となる。しかし$\\lambda \\to \\infty$とすると、罰則項の影響が大きくなり、リッジ回帰係数は0に近づいていく。\n",
    "\n",
    "標準の最小2乗法による回帰係数の推定値は、スケールの変更に対して等価である。つまり、$X_j$を定数$c$倍すると係数は単に$1/c$倍になるだけである。別の言い方をすれば、$j$番目の予測変数がどんなスケールであろうが、$X_j \\hat{\\beta}_i$は不変である。それに対し、リッジ回帰係数は予測変数を定数倍した際には大きく変化する。例えば単位をドルとする変数``income``を考える。この変数の単位として千ドルを使うこともよくあるが、その場合その変数の値は以前の値と1000倍異なる。ここで、式（6.5）のリッジ回帰には係数の平方和の項があるため、このようなスケールの変化は単に``income``のリッジ回帰係数で1000倍を考慮すればよいというわけにはいかない。すなわち、$X_j \\hat{\\beta_{j, \\lambda}^R}$は$\\lambda$の値だけでなく、$j$番目の予測変数のスケールにも依存しているのである。実際のところ、$X_j \\hat{\\beta_{j, \\lambda}^R}$の値は他の予測変数のスケールにも依存しているかもしれない。したがって、すべての変数を同じスケールにするように予測変数を\n",
    "\n",
    "\\begin{equation}\n",
    "    \\tilde{x}_{i, j} = \\frac{x_{ij}}{\\sqrt{\\frac{1}{n}\\sum_{i=1}^n (x_{ij} - \\bar{x}_j)^2}} \\tag{6.6}\n",
    "\\end{equation}\n",
    "\n",
    "により標準化した上で、リッジ回帰を当てはめるのが最も適切である。式(6.6)の分母は、j番目の予測変数の標準偏差の推定値である。結果として、標準化後は、すべての変数の標準偏差は1になる。最終的な結果は予測変数がどのスケールで測られているかに依存しない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### リッジ回帰が最小2乗法よりも優れている理由と欠点\n",
    "\n",
    "リッジ回帰が最小2乗法より優れている理由は、バイアスと分散のトレードオフにある。$\\lambda$が増加するにしたがって、リッジ回帰の柔軟さは減少し、分散は減少するが、バイアスは増加する。\n",
    "\n",
    "$p=45, n=50$のときのあるシミュレーションデータでは、$\\lambda$を適切に選択することで（テキストでは$\\lambda=30$付近）、テストMSEを$\\lambda=0$のときよりも小さくすることができる。\n",
    "\n",
    "一般的に、予測変数と応答変数の関係が線形に近いとき、最小2乗法による回帰係数の推定値はバイアスは小さいが分散は大きいかもしれない。これは訓練データにおける小さな変化が最小2乗法が推定する係数に大きな影響をもたらすということである。特に、$p$が$n$と同程度に大きい場合（テキストでは$p=45, n=50$）最小2乗法による回帰係数の推定値には非常に大きなばらつきがある。また、もし$p > n$であれば、最小2乗法による回帰係数の推定値は一意に定まらない。しかし、その場合でもリッジ回帰はバイアスが少し増える代わりに分散を大きく減少させるので、いい結果が得られる。したがって、リッジ回帰は最小2乗法による回帰係数の推定値の分散が大きいときに最も適している手法である。\n",
    "\n",
    "リッジ回帰は$2^p$個のモデルの探索を必要とする最良部分集合選択において計算量の点で大きな利点をもつ。pの値があまり大きくない場合でさえもこのような探索は計算量が非常に多く、実用的でないこともある。これに対し、どのような$\\lambda$の値についても、リッジ回帰はただ1つのモデルを当てはめる。その当てはめの手順の実行は極めて高速であり、式（6.5）をすべての$\\lambda$について同時に解くのにかかる時間は最小2乗法を1つのモデルに当てはめるのにかかる時間とほぼ同じであることが知られている。\n",
    "\n",
    "一方リッジ回帰には明らかな欠点もある。すべての変数の部分集合を使ったモデルを検討する最良部分集合選択、変数増加法、変数減少法などと異なり、リッジ回帰は$p$個全ての予測変数を含むモデルを扱う。式（6.5）の罰則項は係数を0に向かって縮小はするが、（$\\lambda \\to \\infty$としなければ）正確に0にするわけではない。これ自体は予測精度に関して問題がないかもしれないが、変数の数$p$が大きい場合においてモデルの解釈を困難にする。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso\n",
    "\n",
    "Lassoは比較的近年になって使われるようになった手法であり、リッジ回帰の解釈性の欠点を克服しようとするものである。Lasso係数$\\hat{\\beta}_\\lambda^L$は以下の量を最小化する：\n",
    "\n",
    "\\begin{equation}\n",
    "    \\sum_{i=1}^{n} \\left(y_i - \\beta_0 - \\sum_{j=1}^{p}\\beta_j x_{ij}\\right)^2 + \\lambda \\sum_{j=1}^p |\\beta_j| = \\mathrm{RSS} + \\lambda \\sum_{j=1}^{p} |\\beta_j| \\tag{6.7}\n",
    "\\end{equation}\n",
    "\n",
    "式（6.7）は式（6.5）と同様の形式をもつが、唯一の違いは罰則項が$\\lambda \\sum_{j=1}^{p} |\\beta_j|$となっている（$l_1$ノルム正則化項を使っている）ことである。\n",
    "\n",
    "リッジ回帰と同様、lassoも推定係数を0に向かって縮小するが、lassoの場合は、チューニングパラメータ$\\lambda$が十分大きいときには$l_1$ノルム罰則項がいくつかの係数を正確に0にする効果をもつ。したがって、最良部分集合選択と同様、lassoは変数選択を行う。結果的にlassoによって作られたモデルは一般的にリッジ回帰によるモデルよりも極めて解釈が容易である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lassoとリッジ回帰の比較\n",
    "\n",
    "Lassoはリッジ回帰に対して大きな長所があることは明白である。lassoは予測変数の一部のみを使い、より単純で解釈の容易なモデルを作るからである。どちらの方が予測精度が高いのかについては、lassoとリッジ回帰のどちらかが一貫して他方よりも良いということはない（実際、テキストp208, 209では45個の予測変数を使いそれぞれの性能が良い状況があることが示されている；全てが応答変数に関係するようにシミュレーションデータを作成した場合つまり$\\beta_1, \\ldots, \\beta_{45}$いずれも$0$でない場合にはリッジ回帰の方が性能が良いが、2つしか関係しないようにシミュレーションデータを作成するとlassoの方がバイアス、分散、MSEいずれも性能が良い）。一般には、lassoは、少数の予測変数が主で、その他の係数がとても小さい値または0であるような場合に適していると考えられる。リッジ回帰は応答変数が多くの予測変数の関数で、すべての係数が同程度の値の時に適しているであろう。しかし、応答変数に関係している予測変数の数を実際のデータでは事前に知ることはできない。あるデータセットにおいて、どちらの手法が適しているかを決定するには交差検証などを使うとよい。\n",
    "\n",
    "最小2乗法による推定値の分散が非常に大きい場合には、リッジ回帰と同様lassoもバイアスをわずかに増やす代わりに分散を減少させることができる。結果として予測精度がより高くなる。リッジ回帰と異なる点は、lassoは変数選択を行うので、解釈が容易なモデルが得られるという点である。\n",
    "\n",
    "リッジ回帰にもlassoにも非常に効率的なアルゴリズムがあり、どちらの場合においてもすべての$\\lambda$について回帰係数を求める問題を最小2乗法を一度当てはめるのと同程度の時間で解くことができる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### チューニングパラメータの選択"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "リッジ回帰とlassoでは式（6.5）と（6.7）におけるチューニングパラメータ$\\lambda$の値を決定する方法が必要とされる。交差検証は、この問題に対処する単純な方法である。各$\\lambda$の値について交差検証誤差を計算する。そして、交差検証誤差が最小になるようなチューニングパラメータを選択すればよい。最後に、改めてすべてのデータに最適なチューニングパラメータを使ってモデルを当てはめる。\n",
    "\n",
    "チューニングパラメータに対する交差検証誤差のグラフにおいて、最小2乗法に比べてわずかに縮小が行われていることが確認できるとき（小さい$\\lambda$で「谷」になっているとき；例えばテキストp213では$\\lambda=0.5$のとき）や曲線の谷が明確でないとき（$\\lambda$の値が広範囲で同程度の誤差になるとき）には単に最小2乗法を使うとよいかもしれない。\n",
    "\n",
    "$p=45, n=50$という非常に難しい状況のデータであっても、lassoを適用しCVでチューニングパラメータを選択すれば、シグナル変数のみから構成される正しい変数のセットを選択できることがある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 高次元の場合に考慮すべき事項"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 高次元データ\n",
    "\n",
    "回帰や分類のための統計的手法はほとんどの場合、低次元、すなわち、観測データの数$n$が特徴の数$p$よりもかなり大きい場合を想定している。ここでの次元とは$p$の大きさということである。\n",
    "\n",
    "ここ20年間の技術進歩により、ファイナンス、マーケティング、医療などの様々な分野でデータを集める技術が変革を遂げた。現在では、ほとんど数えきれないほど多くの特徴を集めることが常態化している（つまり$p$が大きい）。$p$は非常に大きいかもしれないが、観測データの数$n$は費用や標本の手に入れやすさ、その他の理由により、限られた数しか手に入らない。以下に2つ例を示す：\n",
    "\n",
    "1. 血圧を予測するのに、年齢、性別、BMIのみを使うのではなく、予測モデルに一塩基遺伝子多型（SNP: single nucleotide polymorphisms, 比較的よく見られる単独DNAの突然変異）を含めるかもしれない。このような場合$n \\approx 200$、また$p \\approx 500,000$となる。\n",
    "2. マーケティングアナリストがオンラインショッピングにおける購買パターンを知りたいという場合に、オンラインユーザがサーチエンジンに入力した単語全てを特徴とすることもできる（これはbag of wordsと呼ばれるモデル）。ある研究者が数百人または数千人のサーチエンジンユーザの同意を得てすべての検索履歴を記録するような場合である。あるユーザについて、p個の単語について検索した（1）または検索しなかった（0）と記録され、大きな2値ベクトルとなる。このとき$n \\approx 1000$で$p$はさらに大きい。\n",
    "\n",
    "観測データの数よりも特徴の数が多いようなデータセットをしばしば高次元という。このような場合、最小2乗法のような古典的アプローチは適していない。高次元データの解析時に起こりうる問題については、$n > p$のときと同様であり、バイアスと分散のトレードオフや過学習などを含んでいる。これらの問題については教師付きの統計的学習を使う際にはいつも考えなければならないが、特徴の数が観測データの数に比べて非常に大きいときは、特に注意が必要である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 高次元の場合における問題点\n",
    "\n",
    "高次元の場合を想定していない統計的手法を使った場合にどのような問題が起きるかを見る。ここでは最小2乗法による回帰を使うが、以下の考え方はロジスティック回帰、線形判別分析、その他の古典的な統計的手法にも当てはまる。\n",
    "\n",
    "特徴の数が観測データの数$n$と同じくらいか、またはより大きい場合、最小2乗法は使うことはできない（使うべきではない）。理由は簡単である；特徴と応答の間に真に関係があるかないかに関わらず、最小2乗法は残差が0になるような完全な当てはめとなる係数の推定値を与えてしまうのである。\n",
    "\n",
    "p=1のとき（線形単回帰）で、データの数が20個と2個の場合を考えてみる。20個のデータがある場合、$n > p$であり、最小2乗法による回帰直線はデータに完全に当てはまることはない。回帰直線は20個のデータをなるべく近似しようとする。その一方、データが2個のみである場合、どのようなデータであろうとも、回帰直線はデータに完全に当てはまる。これは問題である。なぜならば、この完全に当てはまった回帰直線はほぼ間違いなく過学習だからである。つまり、高次元の場合において、訓練データに完全に当てはめることができるが、その結果、得られた線形モデルは別のテストデータでは性能がとても悪くなるであろう。したがって、これでは有益なモデルとは言えない。\n",
    "\n",
    "$C_p$、AIC、BICなどの手法は高次元の状況下においては適切でない。なぜならば、推定値$\\hat{\\sigma}^2$に問題が生じるからである（例えば$\\hat{\\sigma}^2 = \\frac{\\mathrm{RSS}}{n - p - 1}$は0になってしまう）。同様に、高次元においては自由度調整済み$R^2$を使うことにも問題がある。自由度調整済み$R^2$が1となるようなモデルを作ることは簡単になるためである。明らかに高次元の場合により適している他の手法が必要である。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 高次元の場合における回帰分析\n",
    "\n",
    "あまり柔軟ではない最小2乗法によるモデルを当てはめる手法、つまり変数増加法、リッジ回帰、lasso、主成分回帰などが高次元で回帰分析を行う上でとても有利である。要するに、これらの手法は通常の最小2乗法に比べて柔軟でないために、過学習の問題を回避できるのである。\n",
    "\n",
    "lassoのあるシミュレーションからは、テスト誤差は問題の次元（特徴または予測変数の数）が大きくなるにつれて増加する傾向があることが示せる。もちろん、新たにモデルに加えた特徴が本当に応答変数と関係していればこの限りではない。この原理は次元の呪いと呼ばれる。モデルを当てはめるのに使われる特徴の数を多くすればするほどモデルの精度は必ずしも改善しないのである（テキストでは$p=20$から$p=2000$に増えた際にテストMSEがほぼ2倍になっている）。一般には応答変数と本当に関係しているシグナル変数をモデルに加えればモデルの改善に繋がる。しかし応答変数に関係していないノイズ変数を加えてもモデルを悪化させることにしかならず、結果としてテスト誤差を増加させてしまう。これはノイズ変数が問題の次元を上げるので、過学習のリスクをより悪化させ、その一方でテスト誤差を改善しないからである（訓練データでたまたま関係があるように見えたノイズ変数に非ゼロの係数を割り当ててしまう）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 高次元の場合における結果の解釈\n",
    "\n",
    "lasso、リッジ回帰、その他の回帰を高次元の状況において行うとき、得られた結果を読み取るには細心の注意を払う必要がある。高次元の場合は多重共線性は非常に大きな問題である。どの予測変数が本当に応答変数に関係しているのか（そもそも関係している予測変数があるのか）について正確な答えを知ることができないということである。また、回帰に使うべきベストな係数についても正しい答えは分からない。できることと言えば、応答変数の予測に本当に必要な変数に大きな回帰係数が付されていると願うことだけである。\n",
    "\n",
    "例えば、500,000個のSNPをもとに血圧を予測したい場合を考える。変数増加法によって、17個のSNPが訓練データにおいて良い精度を示したとする。これらの17個の変数が、モデルに含まれなかった他の変数よりも血圧を予測するのにより優れていると結論付けることは間違っている。選ばれた17個のSNPのモデルと同程度の精度で血圧を予測できる17個のSNPの組み合わせは他にも多くあることだろう。独立したデータセットが別にあり、そのデータで変数増加法を使えば、異なる、しかも同じ変数を全く含んでいないようなSNPを使ったモデルになることもありうる。これはモデルに価値がないということではない。例えば、そのモデルはある独立した患者のグループの血圧を予測するのに非常に効果的で、したがって臨床現場において医学的にとても役立つということもあるであろう。しかし、得られた結果を過信しないよう注意を払わなければならない。そして、血圧を予測する際、多くのモデルがありうるが、そのうちの1つを見つけたにすぎず、独立したデータセットでさらに検証しなくてはならないことを強く認識しなければならない。\n",
    "\n",
    "高次元の場合は誤差やモデルの当てはめに関する評価については特に注意が必要である。$p > n$である場合、残差が0になる無益なモデルを作ることは簡単である。したがって誤差平方和、p値、$R^2$などの統計量、訓練データでの当てはまりの程度を表す他の古典的な量は、高次元におけるモデルの当てはまりの良さの証拠として決して用いるべきではない。独立したテストデータを使った結果や、交差検証誤差についての報告をすることが重要である。例えば、独立したテストデータを使ってMSEや$R^2$を検証することは有効な方法であるが、訓練MSEは有効ではない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実習2: リッジ回帰とLasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Hitter``データ（野球選手の前年の成績に関する統計データ）でリッジ回帰を使って野球選手の``Salary``を予測することを考える。まずは不完全データ（欠測値を含むデータ）を削除する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV\n",
    "# scale()を用いるため\n",
    "from sklearn.preprocessing import scale\n",
    "# mean_squared_error()を用いるため\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 263 entries, -Alan Ashby to -Willie Wilson\n",
      "Data columns (total 20 columns):\n",
      "AtBat        263 non-null int64\n",
      "Hits         263 non-null int64\n",
      "HmRun        263 non-null int64\n",
      "Runs         263 non-null int64\n",
      "RBI          263 non-null int64\n",
      "Walks        263 non-null int64\n",
      "Years        263 non-null int64\n",
      "CAtBat       263 non-null int64\n",
      "CHits        263 non-null int64\n",
      "CHmRun       263 non-null int64\n",
      "CRuns        263 non-null int64\n",
      "CRBI         263 non-null int64\n",
      "CWalks       263 non-null int64\n",
      "League       263 non-null object\n",
      "Division     263 non-null object\n",
      "PutOuts      263 non-null int64\n",
      "Assists      263 non-null int64\n",
      "Errors       263 non-null int64\n",
      "Salary       263 non-null float64\n",
      "NewLeague    263 non-null object\n",
      "dtypes: float64(1), int64(16), object(3)\n",
      "memory usage: 43.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# RのISLRパッケージからHittersデータをcsvファイルにエクスポートする：\n",
    "# データの保存先に移動してlibrary(ISLR)→data(Hitters, package=\"ISLR\")→write.csv(Hitters, \"Hitters.csv\")\n",
    "\n",
    "df = pd.read_csv('Datasets/Hitters.csv', index_col=0).dropna()\n",
    "df.index.name = 'Player'\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>League</th>\n",
       "      <th>Division</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>Salary</th>\n",
       "      <th>NewLeague</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-Alan Ashby</th>\n",
       "      <td>315</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>3449</td>\n",
       "      <td>835</td>\n",
       "      <td>69</td>\n",
       "      <td>321</td>\n",
       "      <td>414</td>\n",
       "      <td>375</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>632</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>475.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-Alvin Davis</th>\n",
       "      <td>479</td>\n",
       "      <td>130</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>1624</td>\n",
       "      <td>457</td>\n",
       "      <td>63</td>\n",
       "      <td>224</td>\n",
       "      <td>266</td>\n",
       "      <td>263</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>880</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>480.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-Andre Dawson</th>\n",
       "      <td>496</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>5628</td>\n",
       "      <td>1575</td>\n",
       "      <td>225</td>\n",
       "      <td>828</td>\n",
       "      <td>838</td>\n",
       "      <td>354</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>200</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AtBat  Hits  HmRun  Runs  RBI  Walks  Years  CAtBat  CHits  \\\n",
       "Player                                                                      \n",
       "-Alan Ashby      315    81      7    24   38     39     14    3449    835   \n",
       "-Alvin Davis     479   130     18    66   72     76      3    1624    457   \n",
       "-Andre Dawson    496   141     20    65   78     37     11    5628   1575   \n",
       "\n",
       "               CHmRun  CRuns  CRBI  CWalks League Division  PutOuts  Assists  \\\n",
       "Player                                                                         \n",
       "-Alan Ashby        69    321   414     375      N        W      632       43   \n",
       "-Alvin Davis       63    224   266     263      A        W      880       82   \n",
       "-Andre Dawson     225    828   838     354      N        E      200       11   \n",
       "\n",
       "               Errors  Salary NewLeague  \n",
       "Player                                   \n",
       "-Alan Ashby        10   475.0         N  \n",
       "-Alvin Davis       14   480.0         A  \n",
       "-Andre Dawson       3   500.0         N  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "League       object\n",
       "Division     object\n",
       "NewLeague    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandasのデータのデータ型の確認\n",
    "df[['League', 'Division', 'NewLeague']].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 263 entries, -Alan Ashby to -Willie Wilson\n",
      "Data columns (total 6 columns):\n",
      "League_A       263 non-null uint8\n",
      "League_N       263 non-null uint8\n",
      "Division_E     263 non-null uint8\n",
      "Division_W     263 non-null uint8\n",
      "NewLeague_A    263 non-null uint8\n",
      "NewLeague_N    263 non-null uint8\n",
      "dtypes: uint8(6)\n",
      "memory usage: 3.6+ KB\n",
      "               League_A  League_N  Division_E  Division_W  NewLeague_A  \\\n",
      "Player                                                                   \n",
      "-Alan Ashby           0         1           0           1            0   \n",
      "-Alvin Davis          1         0           0           1            1   \n",
      "-Andre Dawson         0         1           1           0            0   \n",
      "\n",
      "               NewLeague_N  \n",
      "Player                      \n",
      "-Alan Ashby              1  \n",
      "-Alvin Davis             0  \n",
      "-Andre Dawson            1  \n"
     ]
    }
   ],
   "source": [
    "# 質的変数を変換しておく\n",
    "# get_dummysはarraylikeオブジェクトを受け取りdataframeを返す\n",
    "dummies = pd.get_dummies(df[['League', 'Division', 'NewLeague']])\n",
    "dummies.info()\n",
    "print(dummies.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 263 entries, -Alan Ashby to -Willie Wilson\n",
      "Data columns (total 19 columns):\n",
      "AtBat          263 non-null float64\n",
      "Hits           263 non-null float64\n",
      "HmRun          263 non-null float64\n",
      "Runs           263 non-null float64\n",
      "RBI            263 non-null float64\n",
      "Walks          263 non-null float64\n",
      "Years          263 non-null float64\n",
      "CAtBat         263 non-null float64\n",
      "CHits          263 non-null float64\n",
      "CHmRun         263 non-null float64\n",
      "CRuns          263 non-null float64\n",
      "CRBI           263 non-null float64\n",
      "CWalks         263 non-null float64\n",
      "PutOuts        263 non-null float64\n",
      "Assists        263 non-null float64\n",
      "Errors         263 non-null float64\n",
      "League_N       263 non-null uint8\n",
      "Division_W     263 non-null uint8\n",
      "NewLeague_N    263 non-null uint8\n",
      "dtypes: float64(16), uint8(3)\n",
      "memory usage: 35.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>League_N</th>\n",
       "      <th>Division_W</th>\n",
       "      <th>NewLeague_N</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-Alan Ashby</th>\n",
       "      <td>315.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>835.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-Alvin Davis</th>\n",
       "      <td>479.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1624.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-Andre Dawson</th>\n",
       "      <td>496.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5628.0</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>828.0</td>\n",
       "      <td>838.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AtBat   Hits  HmRun  Runs   RBI  Walks  Years  CAtBat   CHits  \\\n",
       "Player                                                                         \n",
       "-Alan Ashby    315.0   81.0    7.0  24.0  38.0   39.0   14.0  3449.0   835.0   \n",
       "-Alvin Davis   479.0  130.0   18.0  66.0  72.0   76.0    3.0  1624.0   457.0   \n",
       "-Andre Dawson  496.0  141.0   20.0  65.0  78.0   37.0   11.0  5628.0  1575.0   \n",
       "\n",
       "               CHmRun  CRuns   CRBI  CWalks  PutOuts  Assists  Errors  \\\n",
       "Player                                                                  \n",
       "-Alan Ashby      69.0  321.0  414.0   375.0    632.0     43.0    10.0   \n",
       "-Alvin Davis     63.0  224.0  266.0   263.0    880.0     82.0    14.0   \n",
       "-Andre Dawson   225.0  828.0  838.0   354.0    200.0     11.0     3.0   \n",
       "\n",
       "               League_N  Division_W  NewLeague_N  \n",
       "Player                                            \n",
       "-Alan Ashby           1           1            1  \n",
       "-Alvin Davis          0           1            0  \n",
       "-Andre Dawson         1           0            1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.Salary\n",
    "# 独立変数からなる行列をつくる\n",
    "# dropは dropしたいlist-like Index or column labelsを渡し、dataframeを返す（axis=0なら行方向に、1なら列方向にdropする）\n",
    "X_ = df.drop(['Salary', 'League', 'Division', 'NewLeague'], axis=1).astype('float64')\n",
    "# concatはseriesやdataframeを受け取りseriesやdataframeを返す（axis=0なら行方向に、1なら列方向に結合する）\n",
    "X = pd.concat([X_, dummies[['League_N', 'Division_W', 'NewLeague_N']]], axis=1)\n",
    "X.info()\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>LeagueN</th>\n",
       "      <th>DivisionW</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>NewLeagueN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-Mike Heath</th>\n",
       "      <td>288.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2815.0</td>\n",
       "      <td>698.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-John Russell</th>\n",
       "      <td>315.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-Pete Incaviglia</th>\n",
       "      <td>540.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  AtBat   Hits  HmRun  Runs   RBI  Walks  Years  CAtBat  \\\n",
       "-Mike Heath       288.0   65.0    8.0  30.0  36.0   27.0    9.0  2815.0   \n",
       "-John Russell     315.0   76.0   13.0  35.0  60.0   25.0    3.0   630.0   \n",
       "-Pete Incaviglia  540.0  135.0   30.0  82.0  88.0   55.0    1.0   540.0   \n",
       "\n",
       "                  CHits  CHmRun  CRuns   CRBI  CWalks  LeagueN  DivisionW  \\\n",
       "-Mike Heath       698.0    55.0  315.0  325.0   189.0      1.0        0.0   \n",
       "-John Russell     151.0    24.0   68.0   94.0    55.0      1.0        0.0   \n",
       "-Pete Incaviglia  135.0    30.0   82.0   88.0    55.0      0.0        1.0   \n",
       "\n",
       "                  PutOuts  Assists  Errors  NewLeagueN  \n",
       "-Mike Heath         259.0     30.0    10.0         0.0  \n",
       "-John Russell       498.0     39.0    13.0         1.0  \n",
       "-Pete Incaviglia    157.0      6.0    14.0         0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RではHitters=na.omit(Hitters)→x=model.matrix(Salary~.,Hitters)[,-1]→set.seed(1)→sample()→write.csv()と実行した\n",
    "# model.matrix()は質的変数があれば自動でダミー変数に変換するため計画行列を作成するのに便利な関数である（-1は切片の列）\n",
    "# astype('float64')はstandardScaler()またはscale()のため\n",
    "X_train = pd.read_csv('Datasets/Hitters_X_train.csv', index_col=0).astype('float64')\n",
    "y_train = pd.read_csv('Datasets/Hitters_y_train.csv', index_col=0)\n",
    "X_test = pd.read_csv('Datasets/Hitters_X_test.csv', index_col=0).astype('float64')\n",
    "y_test = pd.read_csv('Datasets/Hitters_y_test.csv', index_col=0)\n",
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# 標準化のための平均と標準偏差を計算する\n",
    "scaler = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142388.81067638902"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Ridge(alpha=1.0)\n",
    "# 学習データを標準化し学習する\n",
    "ridge.fit(scaler.transform(X_train), y_train)\n",
    "# テストデータで予測する\n",
    "pred = ridge.predict(scaler.transform(X_test))\n",
    "mean_squared_error(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtBat         -149.111160\n",
       "Hits           109.234457\n",
       "HmRun           70.378046\n",
       "Runs           -18.727737\n",
       "RBI             -9.910319\n",
       "Walks          101.198612\n",
       "Years         -103.592487\n",
       "CAtBat        -196.124234\n",
       "CHits          309.735609\n",
       "CHmRun          45.556842\n",
       "CRuns            5.048450\n",
       "CRBI           136.690867\n",
       "CWalks          -1.672710\n",
       "PutOuts         40.627245\n",
       "Assists        -76.291624\n",
       "Errors          48.936357\n",
       "League_N        75.934646\n",
       "Division_W     -24.408753\n",
       "NewLeague_N    -12.922267\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 回帰係数を表示する\n",
    "# np.flatten()は配列を1次元化しコピーを返す\n",
    "pd.Series(ridge.coef_.flatten(), index=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "481.79294332074926"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha=1.0のときの回帰係数のノルム\n",
    "np.sqrt(np.sum(ridge.coef_**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224669.88997662338"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 正則化項の影響を強くする\n",
    "ridge.set_params(alpha=10**10)\n",
    "# 単に標準化を行うscale()を使って標準化し学習する\n",
    "# テストデータも同じように標準化するならばStandardScalerを使ってもよい（https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-scaler）\n",
    "ridge.fit(scale(X_train), y_train)\n",
    "pred = ridge.predict(scale(X_test))\n",
    "mean_squared_error(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x    224669.906736\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# リッジ回帰で非常に大きなalphaの値を使うことは、切片のみのモデルを当てはめてテストデータの予測に訓練データの平均を使うことと等価\n",
    "((y_train.mean()-y_test)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtBat          1.941828e-06\n",
       "Hits           2.027949e-06\n",
       "HmRun          2.271090e-06\n",
       "Runs           2.277431e-06\n",
       "RBI            2.453446e-06\n",
       "Walks          2.656953e-06\n",
       "Years          2.043934e-06\n",
       "CAtBat         3.090458e-06\n",
       "CHits          3.212319e-06\n",
       "CHmRun         3.422507e-06\n",
       "CRuns          3.301981e-06\n",
       "CRBI           3.464895e-06\n",
       "CWalks         3.230358e-06\n",
       "PutOuts        1.277013e-07\n",
       "Assists       -1.575202e-06\n",
       "Errors         1.374508e-06\n",
       "League_N       1.517945e-07\n",
       "Division_W    -1.716398e-08\n",
       "NewLeague_N   -3.930355e-08\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha=10**10のときの回帰係数\n",
    "pd.Series(ridge.coef_.flatten(), index=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0238323616801042e-05"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha=10**10のときの回帰係数のノルム\n",
    "# alpha=1.0のときよりも確かに小さくなっている\n",
    "np.sqrt(np.sum(ridge.coef_**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeCV(alphas=array([1.00000e+10, 7.56463e+09, ..., 1.32194e-02, 1.00000e-02]),\n",
       "    cv=None, fit_intercept=True, gcv_mode=None, normalize=False,\n",
       "    scoring='neg_mean_squared_error', store_cv_values=False)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas = 10**np.linspace(10,-2,100)\n",
    "# cvを指定しなければLOOCVが行われる（https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html）\n",
    "# cv=で指定するとiidパラメータのdeprication warningが出てきてしまう\n",
    "# scoringではモデル評価の方法を指定する（https://scikit-learn.org/stable/modules/model_evaluation.html）\n",
    "ridgecv = RidgeCV(alphas=alphas, scoring='neg_mean_squared_error')\n",
    "ridgecv.fit(scale(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.64633275546291"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridgecv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128848.7927451657"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.set_params(alpha=ridgecv.alpha_)\n",
    "ridge.fit(scale(X_train), y_train)\n",
    "mean_squared_error(y_test, ridge.predict(scale(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoCV(alphas=array([1.00000e+10, 7.56463e+09, ..., 1.32194e-02, 1.00000e-02]),\n",
       "    copy_X=True, cv=10, eps=0.001, fit_intercept=True, max_iter=10000,\n",
       "    n_alphas=100, n_jobs=None, normalize=False, positive=False,\n",
       "    precompute='auto', random_state=None, selection='cyclic', tol=0.0001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso()\n",
    "lassocv = LassoCV(alphas=alphas, cv=10, max_iter=10000)\n",
    "# np.ravel()はnp.flatten()より高速だがインプレース（コピーをとらず、そのオブジェクトを直接変更する）なため必要ならflatten()を使う\n",
    "lassocv.fit(scale(X_train), y_train.values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.72267222010321"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lassocv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130685.62080218211"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.set_params(alpha=lassocv.alpha_)\n",
    "lasso.fit(scale(X_train), y_train)\n",
    "mean_squared_error(y_test, lasso.predict(scale(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtBat           0.000000\n",
       "Hits            0.000000\n",
       "HmRun          30.216650\n",
       "Runs            0.000000\n",
       "RBI             0.000000\n",
       "Walks          86.710223\n",
       "Years         -38.658642\n",
       "CAtBat          0.000000\n",
       "CHits          85.746895\n",
       "CHmRun         56.857298\n",
       "CRuns           0.000000\n",
       "CRBI           97.368965\n",
       "CWalks          0.000000\n",
       "PutOuts        21.517098\n",
       "Assists       -66.349728\n",
       "Errors         31.962209\n",
       "League_N       20.278556\n",
       "Division_W     -0.000000\n",
       "NewLeague_N     0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 係数のいくつかは正確に0に縮小推定されている\n",
    "pd.Series(lasso.coef_, index=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "- 落海浩，首藤信通．Rによる統計的学習入門．朝倉書店，2018，403p．\n",
    "- https://github.com/JWarmenhoven/ISLR-python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
